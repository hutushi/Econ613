filter(program != "") %>%
filter(!is.na(school))
dat13 <- datstu %>%
dplyr::select(V1, schoolcode1, schoolcode2, schoolcode3, schoolcode4, schoolcode5, schoolcode6, jssdistrict)
datsss13 <- datsss %>%
filter(!duplicated(schoolcode)) %>%
dplyr::select(schoolcode, sssdistrict)
View(datsss)
View(datsss)
datsss13 <- datsss %>%
filter(!duplicated(schoolcode)) %>%
dplyr::select(schoolcode, sssdistrict)
datsss13 <- datsss %>%
filter(!duplicated("schoolcode")) %>%
dplyr::select(schoolcode, sssdistrict)
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE,
prompt = TRUE
)
library(tidyverse)
library(knitr)
library(kableExtra)
library(ggplot2)
library(dummies)
setwd("/Users/whiz/Documents/GitHub/Econ613/Assignments/A3")
# read data
datstu <- read.csv("Data/datstu_v2.csv")
datjss <- read.csv("Data/datjss.csv")
datsss <- read.csv("Data/datsss.csv")
nstu <- as.numeric(count(datstu))
#number of schools being applied by students (not that in the data of schools, not that with students admitted
nsch <- datstu %>%
gather(key = schoolcode, value = Value, schoolcode1, schoolcode2, schoolcode3, schoolcode4, schoolcode5, schoolcode6)%>%
summarise(distinct_school = n_distinct(Value, na.rm =TRUE))
nsch <- as.numeric(nsch)
npgm <- datstu %>%
gather(key = choicepgm, value = Value, choicepgm1, choicepgm2, choicepgm3, choicepgm4, choicepgm5, choicepgm6)%>%
summarise(distinct_program = n_distinct(Value, na.rm =TRUE))
npgm <- as.numeric(npgm)
table11 <- cbind(nstu, nsch, npgm)
colnames(table11) <- c("student", "school", "program")
kable(table11)
nchoice_pgm <- datstu %>%
select(V1, choicepgm1, choicepgm2, choicepgm3, choicepgm4, choicepgm5, choicepgm6) %>%
gather(key = choicepgm, value = program, choicepgm1, choicepgm2, choicepgm3, choicepgm4, choicepgm5, choicepgm6)
nchoice_pgm <- nchoice_pgm %>%
mutate(id = 1:nrow(nchoice_pgm))
nchoice_sch <- datstu %>%
select(V1, schoolcode1, schoolcode2, schoolcode3, schoolcode4, schoolcode5, schoolcode6, jssdistrict) %>%
gather(key = schoolcode, value = school, schoolcode1, schoolcode2, schoolcode3, schoolcode4, schoolcode5, schoolcode6)
nchoice_sch <- nchoice_sch %>%
mutate(id = 1:nrow(nchoice_sch))
nchoice <- nchoice_sch %>%
full_join(nchoice_pgm, by= c("id", "V1")) %>%
select(V1, school, program, jssdistrict, choicepgm) %>%
filter(program != "") %>%
filter(!is.na(school))
rm(nchoice_pgm, nchoice_sch)
nch <- as.numeric(summarise(nchoice, distinct_choice = n_distinct(program, school)))
dat13 <- datstu %>%
select(V1, schoolcode1, schoolcode2, schoolcode3, schoolcode4, schoolcode5, schoolcode6, jssdistrict)
datsss13 <- datsss %>%
filter(!duplicated(schoolcode)) %>%
dplyr::select(schoolcode, sssdistrict)
out13 <- dat13$V1
for (i in 1:6){
dat <- dat13[,c(1,i+1,8)]
colnames(dat) <- c("id", "schoolcode", "jssdistrict")
dat <- dat %>%
left_join(datsss13, by = "schoolcode") %>%
mutate(same = sssdistrict == jssdistrict) %>%
select(same)
out13 <- cbind(out13, dat)
}
colnames(out13) <- c("id","same1","same2", "same3", "same4", "same5", "same6")
out13[is.na(out13)] <- FALSE
out13 <- out13 %>%
mutate(atleast = same1 + same2 + same3 + same4 + same5 + same6 != 0)
rm(dat)
rm(datsss13)
rm(dat13)
nsame <- as.numeric(sum(out13$atleast))
dat14 <- datstu %>%
select(V1, score, schoolcode1, schoolcode2, schoolcode3, schoolcode4, schoolcode5, schoolcode6, choicepgm1, choicepgm2, choicepgm3, choicepgm4, choicepgm5, choicepgm6, rankplace) %>%
filter(!is.na(rankplace))
dat14 <- dat14 %>%
mutate(admitted = ifelse(rankplace ==1 , schoolcode1,
ifelse(rankplace ==2, schoolcode2,
ifelse(rankplace==3, schoolcode3,
ifelse(rankplace==4, schoolcode4,
ifelse(rankplace==5, schoolcode5,
ifelse(rankplace==6, schoolcode6, NA))))))) %>%
mutate(program = ifelse(rankplace ==1 , choicepgm1,
ifelse(rankplace ==2, choicepgm2,
ifelse(rankplace==3, choicepgm3,
ifelse(rankplace==4, choicepgm4,
ifelse(rankplace==5, choicepgm5,
ifelse(rankplace==6, choicepgm6, NA))))))) %>%
select(V1, score, admitted, program)
table14 <- dat14 %>%
group_by(admitted) %>%
mutate(nadmit = n()) %>%
ungroup() %>%
filter(!is.na(admitted))%>%
select(admitted, nadmit) %>%
distinct()
colnames(table14) <- c("schoolcode","size")
table15 <- dat14 %>%
group_by(admitted) %>%
mutate(cutoff = min(score)) %>%
ungroup() %>%
filter(!is.na(admitted))%>%
select(admitted, cutoff) %>%
distinct()
colnames(table15) <- c("schoolcode","cutoff")
table16 <- dat14 %>%
group_by(admitted) %>%
mutate(quality = mean(score))%>%
ungroup() %>%
filter(!is.na(admitted))%>%
select(admitted, quality) %>%
distinct()
colnames(table16) <- c("schoolcode","size")
datsss2 <- datsss %>%
filter(!duplicated(schoolcode)) %>%
select(!V1)
dat2 <- dat14 %>%
group_by(admitted, program) %>%
mutate(size = n()) %>%
mutate(cutoff = min(score)) %>%
mutate(quality = mean(score))%>%
ungroup() %>%
filter(!is.na(admitted))%>%
select(admitted, program, size, cutoff, quality) %>%
distinct()
colnames(dat2) <- c("schoolcode" , "program", "size", "cutoff", "quality")
dat2 <- dat2 %>%
left_join(datsss2, by = "schoolcode")
colnames(nchoice) <- c("V1", "schoolcode", "program", "jssdistrict", "choice")
datsss3 <- datsss2 %>%
select(schoolcode, ssslong, ssslat)
dat3 <- nchoice %>%
left_join(datjss, by = "jssdistrict") %>%
left_join(datsss3, by = "schoolcode") %>%
mutate(choice_rank = ifelse(choice == "choicepgm1", 1,
ifelse(choice == "choicepgm2", 2,
ifelse(choice == "choicepgm3", 3,
ifelse(choice == "choicepgm4", 4,
ifelse(choice == "choicepgm5", 5, 6
))))))  %>%
select(V1, schoolcode, program, point_x, point_y, ssslong, ssslat, choice_rank)
colnames(dat3) <- c("V1", "schoolcode", "program", "jsslong", "jsslat", "ssslong", "ssslat", "choice_rank")
dat3 <- dat3 %>%
mutate(dist = sqrt((69.172*(ssslong-jsslong)*cos(jsslat/57.3))^2 + (69.172*(ssslat-jsslat))^2))
datind<- datstu %>%
select(V1, score, rankplace)
dat4 <- nchoice %>%
#Recode the schoolcode
mutate(scode_rev = substr(schoolcode, 1, 3)) %>%
#Recode the program
mutate(pgm_rev = ifelse(program == "General Arts" | program == "Visual Arts", "Arts",
ifelse(program == "Business" | program == "Home Economics", "Economics",
ifelse(program == "General Science", "Science", "Others"))))%>%
#Create a new choice variable
unite("choice_rev", scode_rev, pgm_rev, sep = " ", remove= FALSE) %>%
mutate(choice_rank = ifelse(choice == "choicepgm1", 1,
ifelse(choice == "choicepgm2", 2,
ifelse(choice == "choicepgm3", 3,
ifelse(choice == "choicepgm4", 4,
ifelse(choice == "choicepgm5", 5, 6
)))))) %>%
left_join(datind, by = "V1") %>%
filter(!is.na(rankplace)) %>%
mutate(admitted = rankplace == choice_rank) %>%
select(V1, scode_rev, pgm_rev, choice_rev, choice_rank, score, admitted)
#calculate cutoff and quality
dat4choice <- dat4 %>%
filter(admitted == TRUE) %>%
group_by(choice_rev) %>%
#Recalculate the cutoff and the quality
mutate(cutoff = min(score)) %>%
mutate(quality = mean(score))%>%
ungroup() %>%
distinct(choice_rev, cutoff, quality)
# Add distance factor
datdist <- select(dat3, V1, dist, choice_rank)
dat4 <- dat4 %>%
left_join(dat4choice, by = "choice_rev") %>%
left_join(datdist, by = c("V1","choice_rank"))
# Select 20000 with the highest score
stu20000 <- datstu %>%
select(V1, score, agey, male) %>%
arrange(desc(score))
stu20000 <- stu20000[1:20000,]
dat4 <- stu20000 %>%
left_join(dat4, by = c("V1" , "score"))
## interested in the first choice
dat5 <- dat4 %>%
filter(choice_rank == 1) %>%
mutate(choice=as.numeric(factor(choice_rev,ordered=TRUE)))
## Creating X and Y for the model
X <- dat5 %>%
mutate(intercept = 1) %>%
select(intercept, score)
X1 <- as.matrix(X)
Y1 <- dummy("choice_rev", data = dat5, sep="_")
View(X)
beta1 = solve(t(X1) %*% X1) %*% t(X1) %*% Y1
mlogit.ll <- function(beta, X, Y) {
beta <- matrix(beta, nrow = 2, byrow = TRUE)
beta[,1] <- 0
est <- exp(X %*% beta)
Pr <- t(apply(est, 1, function(x) x / sum(x)))
Pr <- Pr*Y
loglikelihood <- sum(log(rowSums(Pr)))
return(-loglikelihood)
}
res <- optim(beta1, mlogit.ll, X = X1, Y = Y1, method = "BFGS")
fit1 <- nlm(mlogit.ll, X1, Y1, beta1)
mlogit.ll <- function(beta) {
beta <- matrix(beta, nrow = 2, byrow = TRUE)
beta[,1] <- 0
est <- exp(X1 %*% beta)
Pr <- t(apply(est, 1, function(x) x / sum(x)))
Pr <- Pr*Y1
loglikelihood <- sum(log(rowSums(Pr)))
return(-loglikelihood)
}
fit1 <- nlm(mlogit.ll, beta1)
fit1 <- multinom(choice_rev ~ score, dat5)
library(nnet)
fit1 <- multinom(choice_rev ~ score, dat5)
View(out13)
View(fit1)
View(fit1)
out3 <- fit1$
fit1
fit1
View(X1)
fit1$fitted.values
out3 <- fit1$fitted.values
View(out3)
View(fit1)
out3 <- fit1$wts
View(out13)
out3 <- fit1$coefnames
out3 <- fit1$coefnames
fit1
out3 <- coef(fit1)
View(out3)
out3 <- t(coef(fit1))
# Marginal Effect
est <- exp(X1 %*% out3)
Pr <- t(apply(est, 1, function(x) x / sum(x)))
### 3) compute B_bar for each household and each regressor
B_bar = Pr %*% t(out3)
### 4) get B_bar for family income for each household and replicated it into 10 column
B_bar <- matrix(rep(B_bar[,1],each=245), ncol=245, byrow=TRUE)
### 5) compute B_j-B_bar for family income
dB <- B_rep-B_bar
### 2) get B_j for income and replicate it n times to create (n by 10) matrix
B_rep <- matrix(rep(out3[1,], each = nrow(Pr)), nrow = nrow(Pr))
### 3) compute B_bar for each household and each regressor
B_bar = Pr %*% t(out3)
### 4) get B_bar for family income for each household and replicated it into 10 column
B_bar <- matrix(rep(B_bar[,1],each=245), ncol=245, byrow=TRUE)
### 5) compute B_j-B_bar for family income
dB <- B_rep - B_bar
out5 <- matrix(fit1$estimate, nrow = 2, byrow = TRUE)
out5 <- t(coef(fit1))
### 3) compute B_bar for each household and each regressor
B_bar = Pr %*% t(out3)
### 4) get B_bar for family income for each household and replicated it into 10 column
B_bar <- matrix(rep(B_bar[,1],each=244), ncol=244, byrow=TRUE)
### 5) compute B_j-B_bar for family income
dB <- B_rep - B_bar
### 6) Calculate Pr_ij(B_j - B_bar) for Family Income
PrOut <- Pr*dB
### 7) find average
ME1 <- data.frame(t(apply(PrOut, 2, mean)))
View(ME1)
### 7) find average
ME1 <- data.frame(t(apply(PrOut, 3, mean)))
### 7) find average
ME1 <- data.frame(t(apply(PrOut, 1, mean)))
View(ME1)
### 7) find average
ME1 <- data.frame(t(apply(PrOut, 2, mean)))
View(ME1)
# Marginal Effect
marginal.mlogit <- funtion(beta){
# Marginal Effect
marginal.mlogit <- function(beta){
est <- exp(X1 %*% beta)
Pr <- t(apply(est, 1, function(x) x / sum(x)))
B_rep <- matrix(rep(out5[1,],each=nrow(Pr)),nrow=nrow(Pr))
B_bar = Pr %*% t(beta)
B_bar <- matrix(rep(B_bar[,1],each=244), ncol=244, byrow=TRUE)
dB <- B_rep - B_bar
PrOut <- Pr*dB
ME1 <- data.frame(t(apply(PrOut, 2, mean)))
return(ME1)
}
marginal.mlogit(out5)
rm(out3)
View(out5)
# Marginal Effect
marginal.mlogit <- function(beta){
est <- exp(X1 %*% beta)
Pr <- t(apply(est, 1, function(x) x / sum(x)))
B_rep <- matrix(rep(out5[1,],each=nrow(Pr)),nrow=nrow(Pr))
B_bar = Pr %*% t(beta)
B_bar <- matrix(rep(B_bar[,1],each=nrow(beta)), ncol=nrow(beta), byrow=TRUE)
dB <- B_rep - B_bar
PrOut <- Pr*dB
ME <- data.frame(t(apply(PrOut, 2, mean)))
return(ME)
}
ME.mlogit <- marginal.mlogit(out5)
# Marginal Effect
marginal.mlogit <- function(beta){
est <- exp(X1 %*% beta)
Pr <- t(apply(est, 1, function(x) x / sum(x)))
B_rep <- matrix(rep(out5[1,],each=nrow(Pr)),nrow=nrow(Pr))
B_bar = Pr %*% t(beta)
B_bar <- matrix(rep(B_bar[,1],each=ncol(beta)), ncol=ncol(beta), byrow=TRUE)
dB <- B_rep - B_bar
PrOut <- Pr*dB
ME <- data.frame(t(apply(PrOut, 2, mean)))
return(ME)
}
ME.mlogit <- marginal.mlogit(out5)
View(ME.mlogit)
# Marginal Effect
marginal.mlogit <- function(beta){
est <- exp(X1 %*% beta)
Pr <- t(apply(est, 1, function(x) x / sum(x)))
B1 <- matrix(rep(out5[1,],each=nrow(Pr)),nrow=nrow(Pr))
B2 <- Pr %*% t(beta)
B2 <- matrix(rep(B_bar[,1],each=ncol(beta)), ncol=ncol(beta), byrow=TRUE)
dB <- B1 - B2
PrOut <- Pr*dB
ME <- data.frame(t(apply(PrOut, 2, mean)))
return(ME)
}
ME.mlogit <- marginal.mlogit(out5)
################################ ECON 613 HW 3 ################################
# Author : Promvarat Pradit
# The list of result objects for each question is listed at the end of this document.
#Set working directory
setwd("C:/Users/promv/Dropbox/Master Course work/Spring 2019/Econ 613 Applied econometric micro/Assignment 3")
#Clear workspcae
rm(list = ls())
# # Time code runtime
# ptm <- proc.time()
# House keeping ---------------------------------------------
#Load required library
#install.packages("ggplot2")
library(ggplot2)
#install.packages("matlib")
library(matlib)
#install.packages("dplyr")
library(dplyr)
#install.packages("caret")
library(caret)
#install.packages("gdata")
library(gdata)
#install.packages("stargazer")
library(stargazer)
#install.packages("mfx")
library(mfx)
#install.packages("bayesm")
library(bayesm)
#install.packages("mclogit")
library(mclogit)
#install.packages("fBasics")
library(fBasics)
#install.packages("dummies")
library(dummies)
set.seed(12345)
# Exercise 1 Data Description ------------------------------------------------
# Load data
data(margarine)
product <- margarine$choicePrice
demos <- margarine$demos
# Exercise 1.1 Average and Dispersion in Product Characteristics
## Generate descriptive statistic
descStat_product <- basicStats(product[,3:ncol(product)])
## Subsetting the whole descriptive statistic table
descStat_product <- descStat_product[c("Mean","Median", "Minimum","Maximum", "Stdev", "Variance"),]
# Exercise 1.2 Market share and market share by product characteristic
## Generate market share by products
### group data by choice and count number of observation for each choice then divide by total observation to get market share
mktShare_product <- product %>% group_by(choice) %>% summarize(count = n()) %>% mutate(MarketShare = count*100/sum(count))
mktShare_product <- mktShare_product[,2:3]
### assign names
prod_name <- colnames(product)[3:ncol(product)]
row.names(mktShare_product) <- prod_name
## Generate market share by type (tub vs stick)
### create group by product type
prod_type <- prod_name
prod_type[endsWith(prod_name,"Stk")] = "Stick"
prod_type[endsWith(prod_name,"Tub")] = "Tub"
### group data by product type and sum market share
mktShare_type <- cbind(mktShare_product,prod_type)
mktShare_type <- mktShare_type %>% group_by(prod_type) %>% summarize(count = sum(count), MarketShare = sum(MarketShare))
## Generate market share by type (tub vs stick)
### create group by brand
prod_brand <- prod_name
prod_brand[startsWith(prod_name,"PPk")] = "PPk"
prod_brand[startsWith(prod_name,"PBB")] = "PBB"
prod_brand[startsWith(prod_name,"PFl")] = "PFl"
prod_brand[startsWith(prod_name,"PHse")] = "PHse"
prod_brand[startsWith(prod_name,"PGen")] = "PGen"
prod_brand[startsWith(prod_name,"PImp")] = "PImp"
prod_brand[startsWith(prod_name,"PSS")] = "PSS"
### group data by brand and sum market share
mktShare_brand <- cbind(mktShare_product,prod_brand)
mktShare_brand <- mktShare_brand %>% group_by(prod_brand) %>% summarize(count = sum(count), MarketShare = sum(MarketShare))
# Exercise 1.3 Mapping between observed attributes and choice
## merge data by hhid
mainData <- merge(product, demos, by = "hhid", all.x= TRUE)
## check if all hhid is found (no NA in income column)
any(is.na(mainData$Income))
## create market share for each product by ...
### Income
### group data by Income group and find market share within the same product
mktShare_map_inc <- mainData %>% group_by(Income,choice) %>% summarize(count = n()) %>% group_by(choice) %>% mutate(sumchoice = sum(count)) %>% mutate(MarketShare = count*100/sumchoice)
mktShare_map_inc <- mktShare_map_inc[,c(1,2,5)]
#### reshape from long to wide
library(reshape2)
mktShare_map_inc <- dcast(mktShare_map_inc, Income ~ choice)
colnames(mktShare_map_inc) <- c("Income",prod_name)
### Family Size| 3 groups : <=2 , 3-4 , >=5
#### create family size tag
FamilySize <- rep("family size <= 2", nrow(mainData))
FamilySize[mainData$Fs3_4==1] <- "family size <= 3-4"
FamilySize[mainData$Fs5.==1] <- "family size >= 5"
#### group data by family size and find market share within the same product
mktShare_map_famSize <- mainData %>% cbind(FamilySize) %>% group_by(FamilySize,choice) %>% summarize(count = n()) %>% group_by(choice) %>% mutate(sumchoice = sum(count)) %>% mutate(MarketShare = count*100/sumchoice)
mktShare_map_famSize <- mktShare_map_famSize[,c(1,2,5)]
#### reshape from long to wide
mktShare_map_famSize <- dcast(mktShare_map_famSize, FamilySize ~ choice)
colnames(mktShare_map_famSize) <- c("Family Size",prod_name)
### Education status| 2 groups : college vs non-college
#### group data by college status and find market share within the same product
mktShare_map_college <- mainData %>% group_by(college,choice) %>% summarize(count = n()) %>% group_by(choice) %>% mutate(sumchoice = sum(count)) %>% mutate(MarketShare = count*100/sumchoice)
mktShare_map_college <- mktShare_map_college[,c(1,2,5)]
#### reshape from long to wide
mktShare_map_college <- dcast(mktShare_map_college, college ~ choice)
row.names(mktShare_map_college) <- c("non-college", "college")
mktShare_map_college <- mktShare_map_college[,2:ncol(mktShare_map_college)]
colnames(mktShare_map_college) <- prod_name
### Job status| 2 groups : white collar vs blue collar
#### group data by job status and find market share within the same product
mktShare_map_job <- mainData %>% group_by(whtcollar,choice) %>% summarize(count = n()) %>% group_by(choice) %>% mutate(sumchoice = sum(count)) %>% mutate(MarketShare = count*100/sumchoice)
mktShare_map_job <- mktShare_map_job[,c(1,2,5)]
#### reshape from long to wide
mktShare_map_job <- dcast(mktShare_map_job, whtcollar ~ choice)
row.names(mktShare_map_job) <- c("blue collar", "white collar")
mktShare_map_job <- mktShare_map_job[,2:ncol(mktShare_map_job)]
colnames(mktShare_map_job) <- prod_name
### Retirement status| 2 groups : retired vs not-retired
#### group data by retirement status and find market share within the same product
mktShare_map_retire <- mainData %>% group_by(retired,choice) %>% summarize(count = n()) %>% group_by(choice) %>% mutate(sumchoice = sum(count)) %>% mutate(MarketShare = count*100/sumchoice)
mktShare_map_retire <- mktShare_map_retire[,c(1,2,5)]
#### reshape from long to wide
mktShare_map_retire <- dcast(mktShare_map_retire, retired ~ choice)
row.names(mktShare_map_retire) <- c("not retired", "retiredr")
mktShare_map_retire <- mktShare_map_retire[,2:ncol(mktShare_map_retire)]
colnames(mktShare_map_retire) <- prod_name
X_ij <- as.matrix(mainData[,3:12] - mainData[,3])
View(mainData)
## create indicator matrix
Indicator <- dummy("choice", data = mainData, sep="_")
View(Indicator)
View(X_ij)
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE,
prompt = TRUE
)
library(tidyverse)
library(knitr)
library(kableExtra)
library(ggplot2)
library(dummies)
setwd("/Users/whiz/Documents/GitHub/Econ613/Assignments/A3")
rm(list = ls())
# read data
datstu <- read.csv("Data/datstu_v2.csv")
datjss <- read.csv("Data/datjss.csv")
datsss <- read.csv("Data/datsss.csv")
nstu <- as.numeric(count(datstu))
#number of schools being applied by students (not that in the data of schools, not that with students admitted
nsch <- datstu %>%
gather(key = schoolcode, value = Value, schoolcode1, schoolcode2, schoolcode3, schoolcode4, schoolcode5, schoolcode6)%>%
summarise(distinct_school = n_distinct(Value, na.rm =TRUE))
nsch <- as.numeric(nsch)
npgm <- datstu %>%
gather(key = choicepgm, value = Value, choicepgm1, choicepgm2, choicepgm3, choicepgm4, choicepgm5, choicepgm6)%>%
summarise(distinct_program = n_distinct(Value, na.rm =TRUE))
npgm <- as.numeric(npgm)
table11 <- cbind(nstu, nsch, npgm)
colnames(table11) <- c("student", "school", "program")
kable(table11)
nchoice_pgm <- datstu %>%
select(V1, choicepgm1, choicepgm2, choicepgm3, choicepgm4, choicepgm5, choicepgm6) %>%
gather(key = choicepgm, value = program, choicepgm1, choicepgm2, choicepgm3, choicepgm4, choicepgm5, choicepgm6)
